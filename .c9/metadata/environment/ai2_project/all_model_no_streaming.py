{"filter":false,"title":"all_model_no_streaming.py","tooltip":"/ai2_project/all_model_no_streaming.py","undoManager":{"mark":2,"position":2,"stack":[[{"start":{"row":11,"column":0},"end":{"row":34,"column":1},"action":"remove","lines":["st.title(\"Chatbot powered by Bedrock with multi-choice model\")","","# Initialize session state if there are no messages","if \"messages\" not in st.session_state:","    st.session_state.messages = []","    st.session_state.token_count = 0","","# Display chat messages","for message in st.session_state.messages:","    with st.chat_message(message[\"role\"]):","        st.markdown(message[\"content\"])","","def clear_screen():","    st.session_state.messages = [{\"role\": \"assistant\", \"content\": \"How may I assist you today?\"}]","    st.session_state.token_count = 0","","# Define model options","MODEL_OPTIONS = {","    \"Claude\": \"anthropic.claude-3-sonnet-20240229-v1:0\",","    \"Llama\": \"meta.llama3-8b-instruct-v1:0\",","    \"AI21 Lab\": \"ai21.j2-mid-v1\",","    \"Amazon Titan\": \"amazon.titan-text-premier-v1:0\",","    \"Mistral\": \"mistral.mistral-large-2402-v1:0\",","}"],"id":2}],[{"start":{"row":5,"column":0},"end":{"row":8,"column":17},"action":"remove","lines":["# Configure logging","#logging.basicConfig(level=logging.DEBUG, format='%(asctime)s %(levelname)s %(message)s')","","# Bedrock runtime"],"id":3}],[{"start":{"row":129,"column":0},"end":{"row":154,"column":34},"action":"remove","lines":["# Sidebar","with st.sidebar:","    st.title('Streamlit Chat')","    st.subheader('With DynamoDB Memory :brain:')","    st.button('Clear Screen', on_click=clear_screen)","    ","    option = st.selectbox(","        \"What model would you like to use?\",","        options=list(MODEL_OPTIONS.keys()))","    st.write(\"You selected:\", option)","","if user_prompt := st.chat_input(\"What's Up?\"):","    st.session_state.messages.append({\"role\": \"user\", \"content\": user_prompt})","","    with st.chat_message(\"user\"):","        st.markdown(user_prompt)","    ","    # Prepare the conversation history for the model","    conversation_history = \"\\n\".join(","        f'{msg[\"role\"]}: {msg[\"content\"]}' for msg in st.session_state.messages","    )","    full_response = get_response(MODEL_OPTIONS[option], conversation_history)","    st.session_state.messages.append({\"role\": \"assistant\", \"content\": full_response})","","    with st.chat_message(\"assistant\"):","        st.markdown(full_response)"],"id":4},{"start":{"row":128,"column":0},"end":{"row":129,"column":0},"action":"remove","lines":["",""]},{"start":{"row":127,"column":22},"end":{"row":128,"column":0},"action":"remove","lines":["",""]}]]},"ace":{"folds":[],"scrolltop":37.20000000000001,"scrollleft":0,"selection":{"start":{"row":70,"column":29},"end":{"row":70,"column":29},"isBackwards":false},"options":{"guessTabSize":true,"useWrapMode":false,"wrapToView":true},"firstLineState":0},"timestamp":1717949016803,"hash":"941b88fa939ac3aaad76f5dc2ed2b0697b0b6c1b"}